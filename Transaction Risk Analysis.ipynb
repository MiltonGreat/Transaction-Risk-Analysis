{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1df20f4-b785-4db9-9fd8-c2a57fb6a028",
   "metadata": {},
   "source": [
    "# Transaction Risk Analysis Code\n",
    "\n",
    "**This code implements a fraud detection system using Local Outlier Factor (LOF) to identify potentially risky transactions.** \n",
    "\n",
    "This project implemented an anomaly detection system using the Local Outlier Factor (LOF) algorithm to identify potentially fraudulent transactions in a simulated financial dataset.\n",
    "\n",
    "#### Key Points About This Approach\n",
    "\n",
    "- It combines both transaction-level and customer behavior features\n",
    "- LOF is particularly good at detecting local anomalies (transactions that are unusual for that specific customer's pattern)\n",
    "- The code handles edge cases (missing customer IDs, single-transaction customers)\n",
    "- The contamination parameter of 0.01 suggests the model expects about 1% of transactions to be fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788cfa6d-4a70-4c3c-8281-c019a88eb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce6b6a6-9e6d-40bc-8377-c77098886a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Sender Name</th>\n",
       "      <th>Sender Account</th>\n",
       "      <th>Recipient Name</th>\n",
       "      <th>Recipient Account</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wire Transfer</td>\n",
       "      <td>Deborah Stuart</td>\n",
       "      <td>GB25YFSJ32955239077145</td>\n",
       "      <td>Daniel Mullen</td>\n",
       "      <td>GB06JCLA52666027047459</td>\n",
       "      <td>6158.14</td>\n",
       "      <td>2022-06-19 05:15:21.098123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check</td>\n",
       "      <td>Jason Wagner</td>\n",
       "      <td>GB61ZBQL97930805722596</td>\n",
       "      <td>Michael Roberts</td>\n",
       "      <td>GB83SHNZ43420904498234</td>\n",
       "      <td>5336.63</td>\n",
       "      <td>2020-11-02 16:34:49.373628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Check</td>\n",
       "      <td>Tina Davis</td>\n",
       "      <td>GB05COMK46550155019277</td>\n",
       "      <td>Kayla Johns</td>\n",
       "      <td>GB74RQHI02704652515696</td>\n",
       "      <td>6916.41</td>\n",
       "      <td>2022-03-24 06:17:17.523424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wire Transfer</td>\n",
       "      <td>Matthew Herrera</td>\n",
       "      <td>GB42DZCA70665166124949</td>\n",
       "      <td>Thomas Guzman</td>\n",
       "      <td>GB40RDOB66268771119965</td>\n",
       "      <td>6607.40</td>\n",
       "      <td>2020-03-15 14:31:01.927106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Check</td>\n",
       "      <td>Eric Adams</td>\n",
       "      <td>GB93FDXA69268202738226</td>\n",
       "      <td>Kayla Cowan</td>\n",
       "      <td>GB79UKKK91772426185654</td>\n",
       "      <td>9285.42</td>\n",
       "      <td>2021-03-18 14:35:56.603051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025</th>\n",
       "      <td>Check</td>\n",
       "      <td>Kathleen Carr</td>\n",
       "      <td>GB39JGHL63974355550775</td>\n",
       "      <td>Jennifer Acosta</td>\n",
       "      <td>GB44OVTN32634517404775</td>\n",
       "      <td>943.63</td>\n",
       "      <td>2022-12-26 03:47:10.229748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>Deposit</td>\n",
       "      <td>Jennifer Lewis</td>\n",
       "      <td>GB80HCSH29479959432011</td>\n",
       "      <td>Thomas Thompson</td>\n",
       "      <td>GB65DMCU14967511343462</td>\n",
       "      <td>3959.86</td>\n",
       "      <td>2022-04-09 09:42:55.043718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>Deposit</td>\n",
       "      <td>Jeffrey Barry</td>\n",
       "      <td>GB50UUEB70881547566660</td>\n",
       "      <td>Brandon Walters</td>\n",
       "      <td>GB29OLCR28467598078146</td>\n",
       "      <td>4197.70</td>\n",
       "      <td>2023-09-14 05:43:01.557469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>Check</td>\n",
       "      <td>Derrick Vazquez</td>\n",
       "      <td>GB95RVHB66145642195021</td>\n",
       "      <td>Carol Williams</td>\n",
       "      <td>GB71ZKBO96054061575689</td>\n",
       "      <td>6164.83</td>\n",
       "      <td>2022-07-06 05:51:10.609749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>Wire Transfer</td>\n",
       "      <td>Patrick Barber</td>\n",
       "      <td>GB45BRVQ83606688311779</td>\n",
       "      <td>Christopher Hall</td>\n",
       "      <td>GB22YEHG77514770610618</td>\n",
       "      <td>2981.50</td>\n",
       "      <td>2020-07-14 00:30:21.524025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5030 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transaction Type      Sender Name          Sender Account  \\\n",
       "0       Wire Transfer   Deborah Stuart  GB25YFSJ32955239077145   \n",
       "1               Check     Jason Wagner  GB61ZBQL97930805722596   \n",
       "2               Check       Tina Davis  GB05COMK46550155019277   \n",
       "3       Wire Transfer  Matthew Herrera  GB42DZCA70665166124949   \n",
       "4               Check       Eric Adams  GB93FDXA69268202738226   \n",
       "...               ...              ...                     ...   \n",
       "5025            Check    Kathleen Carr  GB39JGHL63974355550775   \n",
       "5026          Deposit   Jennifer Lewis  GB80HCSH29479959432011   \n",
       "5027          Deposit    Jeffrey Barry  GB50UUEB70881547566660   \n",
       "5028            Check  Derrick Vazquez  GB95RVHB66145642195021   \n",
       "5029    Wire Transfer   Patrick Barber  GB45BRVQ83606688311779   \n",
       "\n",
       "        Recipient Name       Recipient Account   Amount  \\\n",
       "0        Daniel Mullen  GB06JCLA52666027047459  6158.14   \n",
       "1      Michael Roberts  GB83SHNZ43420904498234  5336.63   \n",
       "2          Kayla Johns  GB74RQHI02704652515696  6916.41   \n",
       "3        Thomas Guzman  GB40RDOB66268771119965  6607.40   \n",
       "4          Kayla Cowan  GB79UKKK91772426185654  9285.42   \n",
       "...                ...                     ...      ...   \n",
       "5025   Jennifer Acosta  GB44OVTN32634517404775   943.63   \n",
       "5026   Thomas Thompson  GB65DMCU14967511343462  3959.86   \n",
       "5027   Brandon Walters  GB29OLCR28467598078146  4197.70   \n",
       "5028    Carol Williams  GB71ZKBO96054061575689  6164.83   \n",
       "5029  Christopher Hall  GB22YEHG77514770610618  2981.50   \n",
       "\n",
       "                       Timestamp  \n",
       "0     2022-06-19 05:15:21.098123  \n",
       "1     2020-11-02 16:34:49.373628  \n",
       "2     2022-03-24 06:17:17.523424  \n",
       "3     2020-03-15 14:31:01.927106  \n",
       "4     2021-03-18 14:35:56.603051  \n",
       "...                          ...  \n",
       "5025  2022-12-26 03:47:10.229748  \n",
       "5026  2022-04-09 09:42:55.043718  \n",
       "5027  2023-09-14 05:43:01.557469  \n",
       "5028  2022-07-06 05:51:10.609749  \n",
       "5029  2020-07-14 00:30:21.524025  \n",
       "\n",
       "[5030 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('synthetic_bank_transfers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e7e7f1-d3ad-4260-89bc-e2697e3ad862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5030 entries, 0 to 5029\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Transaction Type   5030 non-null   object \n",
      " 1   Sender Name        5030 non-null   object \n",
      " 2   Sender Account     5030 non-null   object \n",
      " 3   Recipient Name     5030 non-null   object \n",
      " 4   Recipient Account  5030 non-null   object \n",
      " 5   Amount             5030 non-null   float64\n",
      " 6   Timestamp          5030 non-null   object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 275.2+ KB\n",
      "None\n",
      "             Amount\n",
      "count   5030.000000\n",
      "mean    5286.773097\n",
      "std     3604.408641\n",
      "min      100.950000\n",
      "25%     2700.607500\n",
      "50%     5262.165000\n",
      "75%     7608.537500\n",
      "max    49211.290000\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353c5d5-1664-4ebd-b012-159a776ff282",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e4bba-4543-4d1b-b8e5-9f09e9baa72c",
   "metadata": {},
   "source": [
    "This includes:\n",
    "\n",
    "- Datetime Conversion: Converts Timestamp to datetime to easily extract features like hour, day, and month.\n",
    "- Missing Values Check: Verifies if any columns have missing values. In this case, there appear to be none.\n",
    "- Feature Engineering: Extracts features from the Timestamp column, such as the hour of the transaction, the day of the week, and the month.\n",
    "- Dropping Irrelevant Columns: Removes Sender Name and Recipient Name, as they may not contribute significantly to fraud detection.\n",
    "- Encoding Categorical Variables: Uses one-hot encoding to convert Transaction Type into numerical features.\n",
    "- Standardizing Numerical Features: Scales the Amount column to ensure it is on the same scale as other features (important for models like DBSCAN and LOF that use distance-based metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8848d6d1-5600-4c37-8e88-16aa13c3d7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " Transaction Type     0\n",
      "Sender Name          0\n",
      "Sender Account       0\n",
      "Recipient Name       0\n",
      "Recipient Account    0\n",
      "Amount               0\n",
      "Timestamp            0\n",
      "dtype: int64\n",
      "\n",
      "Data info after preprocessing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5030 entries, 0 to 5029\n",
      "Data columns (total 10 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   Sender Account                  5030 non-null   object        \n",
      " 1   Recipient Account               5030 non-null   object        \n",
      " 2   Amount                          5030 non-null   float64       \n",
      " 3   Timestamp                       5030 non-null   datetime64[ns]\n",
      " 4   Transaction Hour                5030 non-null   int32         \n",
      " 5   Transaction Day                 5030 non-null   int32         \n",
      " 6   Transaction Month               5030 non-null   int32         \n",
      " 7   Weekend                         5030 non-null   int64         \n",
      " 8   Transaction Type_Deposit        5030 non-null   bool          \n",
      " 9   Transaction Type_Wire Transfer  5030 non-null   bool          \n",
      "dtypes: bool(2), datetime64[ns](1), float64(1), int32(3), int64(1), object(2)\n",
      "memory usage: 265.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Convert 'Timestamp' column to datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# 2. Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# 3. Feature engineering (extracting time-based features)\n",
    "df['Transaction Hour'] = df['Timestamp'].dt.hour\n",
    "df['Transaction Day'] = df['Timestamp'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['Transaction Month'] = df['Timestamp'].dt.month\n",
    "df['Weekend'] = df['Transaction Day'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# 4. Drop 'Sender Name' and 'Recipient Name' (if not needed for modeling)\n",
    "df.drop(columns=['Sender Name', 'Recipient Name'], inplace=True)\n",
    "\n",
    "# 5. Encode 'Transaction Type'\n",
    "df = pd.get_dummies(df, columns=['Transaction Type'], drop_first=True)\n",
    "\n",
    "# 6. Standardize 'Amount'\n",
    "scaler = StandardScaler()\n",
    "df['Amount'] = scaler.fit_transform(df[['Amount']])\n",
    "\n",
    "# 7. Check data types\n",
    "print(\"\\nData info after preprocessing:\")\n",
    "print(df.info())\n",
    "\n",
    "# Add customer ID if not present (assuming 'Sender Account' represents customer)\n",
    "df['CustomerID'] = df['Sender Account']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce2eab-91cf-4d8e-b304-4cd8d1687371",
   "metadata": {},
   "source": [
    "**Customer Identification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec4684-6713-4282-9646-ba7cdff236aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First ensure we have a CustomerID column\n",
    "if 'CustomerID' not in df.columns:\n",
    "    # Use 'Sender Account' as CustomerID if available\n",
    "    if 'Sender Account' in df.columns:\n",
    "        df['CustomerID'] = df['Sender Account']\n",
    "    # Alternatively use another identifier if available\n",
    "    elif 'AccountID' in df.columns:\n",
    "        df['CustomerID'] = df['AccountID']\n",
    "    else:\n",
    "        # If no customer identifier exists, create a dummy one\n",
    "        print(\"Warning: No customer identifier found - using transaction index as CustomerID\")\n",
    "        df['CustomerID'] = df.index.astype(str)\n",
    "\n",
    "# 2. Verify the CustomerID exists and has proper values\n",
    "print(\"\\nCustomerID sample values:\")\n",
    "print(df['CustomerID'].head())\n",
    "print(\"\\nNumber of unique customers:\", df['CustomerID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1a05d-8c24-4210-84d6-6e1415a5fd75",
   "metadata": {},
   "source": [
    "**Basic Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d6cf5-e3f3-4f15-a0ce-2052d7618aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Now proceed with the feature engineering\n",
    "transaction_features = df[[\n",
    "    'Amount',\n",
    "    'Transaction Hour',\n",
    "    'Transaction Day',\n",
    "    'Weekend'\n",
    "]].copy()\n",
    "\n",
    "# Add time since last transaction\n",
    "df['TimeSinceLast'] = df.groupby('CustomerID')['Timestamp'].diff().dt.total_seconds()/3600\n",
    "transaction_features['TimeSinceLast'] = df['TimeSinceLast'].fillna(24)  # Default 24h for first transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074ac94-b442-4110-a641-4d66c7a6ea13",
   "metadata": {},
   "source": [
    "**Customer Behavior Features**\n",
    "\n",
    "Only creates customer behavior features if customers have multiple transactions\n",
    "\n",
    "Aggregates by customer to create features like:\n",
    "- Average and standard deviation of transaction amounts\n",
    "- Average transaction time and its consistency\n",
    "- Weekend transaction ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e898f8-b15f-4797-b999-8afc27ca6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create customer behavior features only if we have multiple transactions per customer\n",
    "if df['CustomerID'].nunique() < len(df):\n",
    "    customer_behavior = df.groupby('CustomerID').agg({\n",
    "        'Amount': ['mean', 'std', 'count'],\n",
    "        'Transaction Hour': ['mean', 'std'],\n",
    "        'Weekend': 'mean'\n",
    "    })\n",
    "    customer_behavior.columns = ['_'.join(col).strip() for col in customer_behavior.columns.values]\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    customer_behavior['Amount_coef_var'] = customer_behavior['Amount_std'] / (customer_behavior['Amount_mean'] + 1e-6)\n",
    "    customer_behavior['Hour_consistency'] = customer_behavior['Transaction Hour_std'] / (customer_behavior['Transaction Hour_mean'] + 1e-6)\n",
    "    \n",
    "    # Select features to join\n",
    "    customer_features = customer_behavior[[\n",
    "        'Amount_mean',\n",
    "        'Amount_std',\n",
    "        'Amount_coef_var',\n",
    "        'Hour_consistency',\n",
    "        'Weekend_mean'\n",
    "    ]].rename(columns={'Weekend_mean': 'Weekend_ratio'})\n",
    "    \n",
    "    transaction_features = transaction_features.join(customer_features, on='CustomerID')\n",
    "else:\n",
    "    print(\"Warning: Only one transaction per customer - skipping customer behavior features\")\n",
    "    transaction_features['Amount_mean'] = 0\n",
    "    transaction_features['Amount_std'] = 0\n",
    "    transaction_features['Amount_coef_var'] = 0\n",
    "    transaction_features['Hour_consistency'] = 0\n",
    "    transaction_features['Weekend_ratio'] = 0\n",
    "\n",
    "# Fill NA values\n",
    "transaction_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63acce-860f-45d1-92f0-99f209d23e5b",
   "metadata": {},
   "source": [
    "**LOF Analysis**\n",
    "\n",
    "Applies LOF algorithm with:\n",
    "- Number of neighbors set to minimum of 20 or (number of samples - 1)\n",
    "- Contamination rate of 1% (expecting ~1% outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b8c55f6-7002-4710-a121-ee9d97834efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CustomerID sample values:\n",
      "0    GB25YFSJ32955239077145\n",
      "1    GB61ZBQL97930805722596\n",
      "2    GB05COMK46550155019277\n",
      "3    GB42DZCA70665166124949\n",
      "4    GB93FDXA69268202738226\n",
      "Name: CustomerID, dtype: object\n",
      "\n",
      "Number of unique customers: 5030\n",
      "Warning: Only one transaction per customer - skipping customer behavior features\n",
      "\n",
      "Detected 51 outlier transactions (1.01%)\n",
      "\n",
      "Top 5 riskiest transactions:\n",
      "                     Timestamp              CustomerID     Amount  LOF_Score\n",
      "135 2021-01-26 08:31:18.161286  GB11GJBK55102819390890   5.697275         -1\n",
      "141 2020-12-24 03:23:31.925294  GB52VOFI12376628773685   1.245897         -1\n",
      "257 2022-04-28 07:33:00.782881  GB82QLJW69004109738010  -1.434046         -1\n",
      "332 2022-12-05 22:31:18.056673  GB18EUSO29562851939941   2.012662         -1\n",
      "369 2021-03-14 01:10:58.072148  GB90GFRK74601695010029  12.187543         -1\n"
     ]
    }
   ],
   "source": [
    "# 5. Proceed with LOF analysis\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_lof = scaler.fit_transform(transaction_features)\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=min(20, len(X_lof)-1), contamination=0.01)\n",
    "df['LOF_Score'] = lof.fit_predict(X_lof)\n",
    "df['LOF_Outlier'] = (df['LOF_Score'] == -1).astype(int)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nDetected {df['LOF_Outlier'].sum()} outlier transactions ({df['LOF_Outlier'].mean():.2%})\")\n",
    "print(\"\\nTop 5 riskiest transactions:\")\n",
    "print(df.nsmallest(5, 'LOF_Score')[['Timestamp', 'CustomerID', 'Amount', 'LOF_Score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa117e09-4663-4aeb-b48d-14c403dc3cf5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "While this implementation successfully identified structural outliers, true fraud detection requires richer transaction history and labeled data. Future work should focus on expanding the dataset, refining features, and validating results against known fraud cases to build a more robust risk-scoring system.\n",
    "\n",
    "The analysis successfully flagged 1% of transactions (51 outliers) as high-risk based on features such as:\n",
    "\n",
    "- Transaction Amount (including negative values, which may indicate reversals)\n",
    "- Time of Transaction (early morning/late-night transactions were flagged)\n",
    "- Weekend vs. Weekday Activity\n",
    "- Time Since Last Transaction (though limited due to single-transaction-per-customer data)\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. Data Limitations:\n",
    "\n",
    "The dataset contained only one transaction per customer, preventing the model from learning customer-specific behavioral patterns.\n",
    "\n",
    "Without historical data, the model could only detect global anomalies (e.g., extreme amounts, unusual times) rather than customer-specific deviations.\n",
    "\n",
    "2. Detected Anomalies:\n",
    "\n",
    "The riskiest transactions included:\n",
    "- A negative amount (possible refund or error)\n",
    "- Late-night/early-morning transactions\n",
    "- Unusually high amounts compared to the dataset’s distribution\n",
    "\n",
    "3. Model Performance:\n",
    "- The LOF algorithm performed as expected, flagging 1% of transactions (matching the contamination=0.01 parameter).\n",
    "- However, without labeled fraud cases, we cannot yet measure precision or recall (i.e., how many flagged transactions are truly fraudulent)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
